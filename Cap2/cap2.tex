\label{cap:metodo}
\section{Notação Musical}

Para este trabalho será necessário um conhecimento prévio de teoria e notação musical moderna. O conhecimento básico necessário para o entendimento do que será exposto a seguir está no Apêndice \ref{ape:notacao}.
Digitalmente, as composições podem ser representadas pelo padrão MIDI.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Arquivos MIDI}

Trata-se de um padrão que descreve um protocolo de comunicação que permite a representação e execução de instrumentos musicais eletrônicos \cite{midi}. O padrão MIDI é capaz de representar uma composição musical, com seus diversos intrumentos, de forma similar à capacidade da notação moderna da partitura. Nas diversas \textit{tracks} do arquivo, ele armazena todas notas e acordes tocados por um instrumento, assim como a duração de cada evento.

O padrão MIDI representa, em 7 bits, as notas das oitavas $-1$ a $9$, que abrange praticamente toda a extensão do som audível pelo ser-humano.

A existência de softwares que convertem do padrão MIDI para padrões mais amigáveis a humanos permite que as composições musicais sejam transcritas para esse padrão e disponibilizadas facilmente \textit{online}. Estes softwares são chamados de sequenciadores. Dois desses softwares foram utilizados no decorrer deste trabalho: Online Sequencer \cite{sequencer} e MuseScore \cite{musescore}, sendo o segundo mais completo e que permite a rápida transcrição do arquivo MIDI em partitura.

É o padrão mais natural a ser escolhido como entrada das análises que foram feitas neste trabalho pois consegue representar digitalmente de forma simples o que é exposto em uma partitura. Há ainda bibliotecas, como \textit{music21}, que auxiliam na leitura desses arquivos e processamento para que seja fácil utilização.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Fundamentação Teórica}
\subsection{Variáveis aleatórias}
\label{sec:prob}

É a variável cujos valores possíveis são os resultados numéricos de um fenômemo aleatório. Uma variável aleatório discreta é aquela que pode assumir apenas uma quantidade discreta e finita de valores. \cite{estocastico}.

No contexto deste trabalho, cada instante de uma música pode ser modelado como um conjunto de variáveis aleatórias discretas. Uma delas representa o som que está sendo emitido. Isto pode ser representado de 3 formas distintas:

\begin{itemize}
    \item Nota, acorde ou pausa;
    \item Par de notas emitidos no instante atual e no anterior;
    \item Distância da nota atual para a nota anterior.
\end{itemize}

A segunda variável aleatória é a duração do evento descrito anteriormente.

A função de probabilidade $P(X)$ é aquela que descreve a lista de probabilidades para cada um dos valores possíveis para o evento observado. Neste trabalho, esta função, para todos os modelos descritos, pode ser obtida através de uma análise de frequência da composição a ser analisada.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Entropia}

Entropia da informação é definida como a quantidade de informação produzida por um processo estocástico. É a grandeza que procura medir a incerteza ou a taxa na qual informação é gerada ou transmitida.

Considerando um evento $X$ que pode assumir os valores ${x_1, x_2, ..., x_n}$, onde se conhece a probabilidade $P(x_i)$ para cada valor, pretende-se medir quanta informação é transmitida por cada valor. Para isso, deve-se encontrar uma função $H(X)$ com as seguintes propriedades \cite{shannon}:

\begin{itemize}
    \item $H$ deve ser contínua em X;
    \item Se $P(x_i)$ é igual para todo $i$, isto é, $P(x_i) = \frac{1}{n}$, então $H$ deve ser monótona crescente em $n$, isto é, para escolhas equiprováveis, quanto mais valores possíveis maior é a incerteza associada;
    \item Se uma escolha pode ser dividida em duas escolhas sucessivas, o valor de $H$ deve ser igual a soma ponderada dos valores individuais de $H$. 
\end{itemize}

A função $H$, entropia de X, que satisfaz as propriedades é \cite{shannon}:

\begin{equation}
    H(X) = - K \sum_{i=1}^{n} P_X(x_i) \log_b{[P_X(x_i)]}
\label{eq:entropy}
\end{equation}
$K$ é uma constante positiva que define a unidade. Será usado o valor $K=1$ aqui em diante. Será utilizado, também, $b=2$. Assim, temos o resultado em bits.

Algumas propriedades da função de entropia são \cite{livro}:

\begin{enumerate}
    \item $H(X) \geq 0$
    \item $H(X|Y) \leq H(X)$. O condicionamento de duas variáveis diminui a entropia. A igualdade ocorre quando X e Y são independentes.
    \item $H(X, Y) \leq H(X) + H(Y)$. Igualdade ocorre quando $X$ e $Y$ são independentes.
\end{enumerate}

Pode-se ainda calcular a entropia no instante da música, isto é, a quantidade de bits necessária para se transmitir o evento em cada instante da música. Este valor pode ser dado por:

\begin{equation}
    H_X(t) = - \log_2{P_X(x_t)} 
\end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Entropia Condicional}

Pode-se definir Entropia Conjunta de duas variáveis aleatórias $X$ e $Y$ da mesma forma expressa na equação \ref{eq:entropy}, utilizando $(X, Y)$ como uma única variável aleatória vetorial. Já utilizando os valores definidos para $K$ e $b$ temos \cite{livro}:

\begin{equation}
    H(X) = - \sum_{x \in X}\sum_{y \in Y} P(x_i, y_i) \log_2{P(x_i, y_i)}
\label{eq:joint_entropy}
\end{equation}

Esse valor também pode ser representado da seguinte forma \cite{livro}:

\begin{equation}
    H(X) = - E \log_2{P(X, Y)}
\end{equation}

A partir desse valor, pode-se calcular o valor da Entropia Condicional \cite{livro}:

\begin{equation}
    H(Y|X) = - E_{P(X,Y)} \log_2{P(Y|X)}
\end{equation}

A partir do valor da função de probabilidade conjunta $P(X,Y)$, pode-se calcular o valor da Entropia Condicional através da equação \cite{livro}:

\begin{equation}
    H(X) = - \sum_{x \in X}\sum_{y \in Y} P(x_i, y_i) \log_2{\frac{P(x_i, y_i)}{P(x_i)}}
\end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Informação Mútua}

Informação Mútua é a entropia relativa entre a distribuição conjunta $P(X,Y)$ e o produto das distribuições $P(X)$ e $P(Y)$. \cite{livro}

Através desta definição, da equação \ref{eq:joint_entropy} e do Teorema de Bayes \cite{bayes} temos:

\begin{equation}
    I(X;Y) = H(X) - H(X|Y) = H(Y) - H(Y|X)
\end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Modelo}

Uma composição musical, ou uma de suas vozes, pode ser observada como uma sequência de notas, acodes e / ou pausas com uma duração associada. Assim, pode-se modelar cada instante da música como duas variáveis aleatórias:

\begin{enumerate}
    \item Nota, Acorde ou Pausa
    \item Duração
\end{enumerate}

Ao realizar o pré-processamento da composição, foram feitas algumas considerações:

\subsection{Extração da Melodia}

Tanto as composições musicais mais clássicas como as mais modernas apresentam diversos instrumentos ou vozes simultaneamente. Cada instrumento desempenha um papel diferente e devemos, então, escolher os mais adequados à nossa análise.

Para propósitos deste trabalho, foi feita a extração apenas da sequência principal, ou melodia, de cada uma das composições utilizadas. Essa extração foi feita utilizando o software MuseScore \cite{musescore}, que permite a vizualização de arquivos MIDI em formato mais amigável para um humano, assim como edição dos mesmos.


\subsection{Função probabilidade}

Para as análises de entropia é necessário que estabeleçamos a função de distribuição de probabilidade $P(X)$ dos eventos que serão analisados. Esse valor foi obtido experimentalmente através de análise de frequência das composições que foram estudadas.

Foi obtido o valor da função para todos os modelos citados na seção \ref{sec:prob}.

As simplificações adotadas no processamento das sequências estão expostas a seguir.

\subsection{Altura da nota}\label{section:altura_da_nota}

As notas de mesmo nome observadas em escalas diferentes foram tratadas com o mesmo valor, por exemplo, a nota Dó foi tratada com o mesmo valor se está na primeira oitava ($C_1$) ou na quarta oitava ($C_4$). Isto deve-se ao fato de que, em uma mesma escala, as notas de mesmo nome em oitavas diferentes carregam, muitas vezes, a mesma informação.

\subsection{Acordes}

Para os acordes, foi tomada duas abordagens diferentes:

\begin{enumerate}
    \item Considerar um acorde como um evento próprio, após o devido tratamento que consiste em simplificar as notas em oitavas diferentes, como foi explicitado em \ref{section:altura_da_nota}, e também ignorar a repetição de notas iguais, por exemplo, o acorde ($C3$, $E3$, $C4$) é tratado como ($C$, $E$).

    \item Utilizar a Nota fundamental do acorde para representar o evento. Por exemplo, o acorde ($C3$, $E3$, $C4$), nesse caso, é tratado como a nota $C$ sendo tocada individualmente
\end{enumerate}

As notas de mesmo nome observadas em escalas diferentes foram tratadas com o mesmo valor, por exemplo, a nota Dó foi tratada com o mesmo valor se está na primeira oitava ($C1$) ou na quarta oitava ($C4$). Isto deve-se ao fato de que, em uma mesma escala, as notas de mesmo nome em oitavas diferentes carregam, muitas vezes, a mesma informação.

\subsection{Distâncias entre notas consecutivas}

Para a análise com a utilização do evento Distância entre notas consecutivas foram tomadas duas abordagens:

\begin{enumerate}
    \item Distância entre as duas notas em semitons, equivalente a diferença do valor MIDI para as duas notas.
    \item Distância entre as duas notas na escala em que a música foi composta.
\end{enumerate}

\subsection{Duração}

A duração dos eventos foi tratada como uma variável aleatória independente do evento. A função de probabilidade também foi obtida através da análise de frequência destes eventos.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Método de Análise}

Após o pré-processamento dos dados e simplificações mencionadas, se obtém os valores para a função de probabilidade para os modelos citados na seção \ref{sec:prob}.

Calculada a função de probabilidade, pode-se calcular os valores de entropia média para as composições, assim como os valores de entropia para cada instante. 

Outros valores e comparações serão introduzidos no próximo capítulo, como, por exemplo, a entropia média por compasso.
